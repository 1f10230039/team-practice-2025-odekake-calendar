import { NextResponse } from "next/server";
import { createClient } from "@supabase/supabase-js";
import OpenAI from "openai";

// ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
const openaiApiKey = process.env.NEXT_PUBLIC_OPENAI_API_KEY;
const openaiApiBase = process.env.NEXT_PUBLIC_OPENAI_API_BASE;

if (!supabaseUrl || !supabaseAnonKey || !openaiApiKey || !openaiApiBase) {
  throw new Error(
    "ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env.local`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
  );
}

// ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
const supabase = createClient(supabaseUrl, supabaseAnonKey);
const openai = new OpenAI({ apiKey: openaiApiKey, baseURL: openaiApiBase });

// OpenAIã®Embeddingãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹é–¢æ•°
async function getEmbedding(text) {
  const result = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: text,
  });
  return result.data[0].embedding;
}

// ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ã£ã¦é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°
async function getRelatedEvents(embedding) {
  const { data: relatedEvents, error } = await supabase.rpc("match_events", {
    query_embedding: embedding,
    match_threshold: 0.5,
    match_count: 5,
  });

  if (error) {
    console.error("ãƒ™ã‚¯ãƒˆãƒ«ã®æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
    return null;
  }

  return relatedEvents;
}

// OpenAIã«æ¸¡ã™ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
function buildPrompt(query, relatedEvents, history) {
  if (relatedEvents && relatedEvents.length > 0) {
    const context = relatedEvents
      .map(event => `ã‚¤ãƒ™ãƒ³ãƒˆå: ${event.name}\nèª¬æ˜Ž: ${event.content}`)
      .join("\n\n");

    return `
ã‚ãªãŸã¯å…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå‹é”ã®ã‚ˆã†ãªAIã‚¤ãƒ™ãƒ³ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼âœ¨
ä»¥ä¸‹ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’ã€ã‚¿ãƒ¡å£ã§ã€è¨˜å·ã‚„çµµæ–‡å­—ã‚’ãŸãã•ã‚“ä½¿ã£ã¦ã€æ¥½ã—ãå›žç­”ã—ã¦ã­ï¼
å›žç­”ã¯ã€ç°¡æ½”ã‹ã¤è¦ç‚¹ã‚’ã¾ã¨ã‚ãŸæ–‡ç« é‡ã«æŠ‘ãˆã€å¥èª­ç‚¹ã€Œã€‚ã€ã®å¾Œã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã€ç®‡æ¡æ›¸ãã®ã‚ˆã†ã«è¦‹ã‚„ã™ãã—ã¦ã­ï¼
è³ªå•ãŒã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ç›´æŽ¥é–¢ä¿‚ãªã„å ´åˆã§ã‚‚ã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ä¸€èˆ¬å¸¸è­˜ã®ç¯„å›²ã§å›žç­”ã‚’è©¦ã¿ã¦ã­ï¼

ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿:
---
${context}
---

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:
${query}

å›žç­”:
`;
  } else {
    return `
ã‚ãªãŸã¯å…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå‹é”ã®ã‚ˆã†ãªAIã‚¤ãƒ™ãƒ³ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼âœ¨
ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§æ¤œç´¢ã‚’è©¦ã¿ãŸã‘ã©ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã‹ã£ãŸã¿ãŸã„...ðŸ˜­
ã€Œã”ã‚ã‚“ã€ãã®æƒ…å ±ã¯è¦‹ã¤ã‘ã‚‰ã‚Œãªã‹ã£ãŸã‚ˆã€ã¨ã„ã†æ—¨ã‚’ã‚¿ãƒ¡å£ã§ä¼ãˆã€ä»–ã«æ‰‹ä¼ãˆã‚‹ã“ã¨ãŒãªã„ã‹èžã„ã¦ã¿ã¦ã­ï¼
å›žç­”ã¯ã€ç°¡æ½”ã‹ã¤è¦ç‚¹ã‚’ã¾ã¨ã‚ãŸæ–‡ç« é‡ã«æŠ‘ãˆã€å¥èª­ç‚¹ã€Œã€‚ã€ã®å¾Œã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã€ç®‡æ¡æ›¸ãã®ã‚ˆã†ã«è¦‹ã‚„ã™ãã—ã¦ã­ï¼

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:
${query}

å›žç­”:
`;
  }
}

// APIãƒ«ãƒ¼ãƒˆã®POSTãƒãƒ³ãƒ‰ãƒ©
export async function POST(req) {
  try {
    const { query, history } = await req.json();

    const queryEmbedding = await getEmbedding(query);

    const relatedEvents = await getRelatedEvents(queryEmbedding);

    const prompt = buildPrompt(query, relatedEvents, history);

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        ...history.map(msg => ({
          role: msg.isUser ? "user" : "assistant",
          content: msg.text,
        })),
        { role: "user", content: prompt },
      ],
    });

    const responseText = completion.choices[0].message.content;

    return NextResponse.json({ text: responseText });
  } catch (error) {
    console.error("API Error:", error);
    return NextResponse.json(
      { error: "Failed to generate response" },
      { status: 500 }
    );
  }
}
